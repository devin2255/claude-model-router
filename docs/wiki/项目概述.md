# 项目概述

## 项目背景

model-router 诞生于 Claude Code 用户在使用不同 AI 模型时的实际需求。Claude Code 原生使用 Anthropic 的 `/v1/messages` API，但用户可能需要：

1. **在中国大陆使用**：需要切换到 Kimi（Moonshot）等国内可用的模型服务
2. **使用 OpenAI 兼容 API**：许多第三方服务（如 OpenRouter）只提供 `/v1/chat/completions` 接口
3. **快速切换模型**：在不同场景下需要在多个模型提供商之间灵活切换

## 核心功能

### 1. 模型配置管理

| 模型 | 提供商 | API 端点 | 默认模型 |
|------|--------|----------|----------|
| kimi | Moonshot | `https://api.moonshot.cn/anthropic` | `kimi-k2.5` |
| openai | OpenAI | `http://127.0.0.1:19000` (代理) | `gpt-5.2-codex` |

### 2. 环境变量自动配置

切换模型时自动设置以下环境变量：

- `ANTHROPIC_BASE_URL` - API 基础地址
- `ANTHROPIC_AUTH_TOKEN` - 认证令牌
- `ANTHROPIC_MODEL` - 默认模型名称
- `ANTHROPIC_DEFAULT_OPUS_MODEL` - Opus 级别模型
- `ANTHROPIC_DEFAULT_SONNET_MODEL` - Sonnet 级别模型
- `ANTHROPIC_DEFAULT_HAIKU_MODEL` - Haiku 级别模型
- `CLAUDE_CODE_SUBAGENT_MODEL` - 子代理模型
- `MODEL_ROUTER_ACTIVE_MODEL` - 当前激活的模型
- `MODEL_ROUTER_PROXY_URL` - 代理服务器地址（OpenAI 模式）
- `MODEL_ROUTER_OPENAI_BASE_URL` - OpenAI 上游地址

### 3. 智能 IP 检测

- 自动检测公网 IP 归属地
- 中国大陆默认使用 `kimi`
- 其他地区默认使用 `openai`
- 支持多个 IP 检测服务（ipapi.co、ipinfo.io、ip-api.com）

### 4. 协议转换代理

当使用 OpenAI 模型时，自动启动本地代理服务器：

- 监听地址：`http://127.0.0.1:19000`
- 将 Anthropic `/v1/messages` 请求转换为 OpenAI `/v1/chat/completions` 或 `/v1/responses`
- 支持流式响应（SSE）
- 自动处理工具调用（Function Calling）

## 适用场景

### 场景一：国内开发者使用 Claude Code

```bat
# 自动检测 IP 并使用 Kimi
model-router model

# 或手动指定
model-router kimi
```

### 场景二：使用 OpenAI 或第三方 API

```bat
# 设置自定义 OpenAI 端点
set MODEL_ROUTER_OPENAI_BASE_URL=https://api.openai.com/v1
model-router openai
```

### 场景三：快速启动 Claude CLI

```bat
# 自动配置环境并启动 Claude
model-router claude
```

## 系统要求

- **操作系统**：Windows（使用 Windows 注册表 API）
- **Python**：3.6+
- **权限**：管理员权限（用于写入系统环境变量）

## 相关源码文件

- `model-router.py:20-39` - 模型配置定义（ENV_BY_MODEL）
- `model-router.py:41-52` - 配置键列表（CONFIG_KEYS）
- `model-router.py:596-651` - IP 地理检测逻辑
